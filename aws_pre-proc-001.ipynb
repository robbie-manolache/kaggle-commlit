{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CommLit: Raw Data Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import AWS packages\r\n",
    "aws = False\r\n",
    "if aws:\r\n",
    "    import boto3\r\n",
    "\r\n",
    "# import regular packages\r\n",
    "import os\r\n",
    "import pyarrow as pa\r\n",
    "import pyarrow.parquet as pq\r\n",
    "from tqdm import tqdm\r\n",
    "import pandas as pd\r\n",
    "import spacy\r\n",
    "\r\n",
    "# set environment\r\n",
    "import commlit as cl\r\n",
    "cl.env_config(\"config.json\")\r\n",
    "comp_dir = os.path.join(os.environ.get(\"DATA_DIR\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value for DATA_DIR has been set!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# NLP model\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")\r\n",
    "tag_df = cl.gen_tag_df(nlp.pipe_labels['tagger'])\r\n",
    "\r\n",
    "# Word frequencies\r\n",
    "freq_df = pd.read_csv(os.path.join(comp_dir, \"google-books-common-words.txt\"),\r\n",
    "                      delimiter=\"\\t\", header=None)\r\n",
    "freq_df.columns = [\"word\", \"count\"]\r\n",
    "freq_df.loc[:, \"word\"] = freq_df[\"word\"].str.lower()\r\n",
    "\r\n",
    "# Training data\r\n",
    "train_df = pd.read_csv(os.path.join(comp_dir, \"train.csv\"))\r\n",
    "train_df = train_df[[\"id\", \"excerpt\", \"target\", \"standard_error\"]]\r\n",
    "train_df.sample(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['google-books-common-words.txt',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word Feature Extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# set up tuples to iterate through and empty list for processed data collection\r\n",
    "doc_tups = list(train_df[[\"excerpt\",\"id\"]].itertuples(index=False, name=None))\r\n",
    "df_list = []\r\n",
    "\r\n",
    "# iterate through doc_tups\r\n",
    "for doc, i in tqdm(nlp.pipe(doc_tups, as_tuples=True)):\r\n",
    "    \r\n",
    "    # process word features and append\r\n",
    "    token_df = cl.gen_raw_word_features(doc, tag_df, freq_df)\r\n",
    "    token_df.loc[:, \"id\"] = i\r\n",
    "    df_list.append(token_df)\r\n",
    "\r\n",
    "# compile word feature data\r\n",
    "df = pd.concat(df_list, ignore_index=True)\r\n",
    "df.shape\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2834it [12:16,  3.85it/s]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('maindev': conda)"
  },
  "interpreter": {
   "hash": "8ef5afb6cf1f6c39027afcc5ffa2be2d0694f57907bf88ebd75e0075e6672cb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}