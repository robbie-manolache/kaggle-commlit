{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommLit: Raw Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for DATA_DIR has been set!\n"
     ]
    }
   ],
   "source": [
    "# import AWS packages\n",
    "aws = True\n",
    "if aws:\n",
    "    import boto3\n",
    "\n",
    "# import regular packages\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# set environment\n",
    "import commlit as cl\n",
    "cl.env_config(\"config.json\")\n",
    "comp_dir = os.path.join(os.environ.get(\"DATA_DIR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>90d8170d5</td>\n",
       "      <td>Kwesi's parents were Papa and Maame. Maame alw...</td>\n",
       "      <td>-1.061225</td>\n",
       "      <td>0.473119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>916faaa6b</td>\n",
       "      <td>The respiratory system (called also respirator...</td>\n",
       "      <td>-1.474937</td>\n",
       "      <td>0.492069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>823f90bf4</td>\n",
       "      <td>There were no mice for kitty, and what could s...</td>\n",
       "      <td>0.666116</td>\n",
       "      <td>0.532948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            excerpt    target  \\\n",
       "826   90d8170d5  Kwesi's parents were Papa and Maame. Maame alw... -1.061225   \n",
       "555   916faaa6b  The respiratory system (called also respirator... -1.474937   \n",
       "2056  823f90bf4  There were no mice for kitty, and what could s...  0.666116   \n",
       "\n",
       "      standard_error  \n",
       "826         0.473119  \n",
       "555         0.492069  \n",
       "2056        0.532948  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tag_df = cl.gen_tag_df(nlp.pipe_labels['tagger'])\n",
    "\n",
    "# Word frequencies\n",
    "freq_df = pd.read_csv(os.path.join(comp_dir, \"google-books-common-words.txt\"),\n",
    "                      delimiter=\"\\t\", header=None)\n",
    "freq_df.columns = [\"word\", \"count\"]\n",
    "freq_df.loc[:, \"word\"] = freq_df[\"word\"].str.lower()\n",
    "\n",
    "# Training data\n",
    "train_df = pd.read_csv(os.path.join(comp_dir, \"train.csv\"))\n",
    "train_df = train_df[[\"id\", \"excerpt\", \"target\", \"standard_error\"]]\n",
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2834it [06:39,  7.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(573290, 151)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up tuples to iterate through and empty list for processed data collection\n",
    "doc_tups = list(train_df[[\"excerpt\",\"id\"]].itertuples(index=False, name=None))\n",
    "df_list = []\n",
    "\n",
    "# iterate through doc_tups\n",
    "for doc, i in tqdm(nlp.pipe(doc_tups, as_tuples=True)):\n",
    "    \n",
    "    # process word features and append\n",
    "    token_df = cl.gen_raw_word_features(doc, tag_df, freq_df)\n",
    "    token_df.loc[:, \"id\"] = i\n",
    "    df_list.append(token_df)\n",
    "\n",
    "# compile word feature data\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join(comp_dir, \"raw_feats.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ef5afb6cf1f6c39027afcc5ffa2be2d0694f57907bf88ebd75e0075e6672cb9"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
